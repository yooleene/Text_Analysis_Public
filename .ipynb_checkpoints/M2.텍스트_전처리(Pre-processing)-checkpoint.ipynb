{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Chapter 2.텍스트_전처리(Pre-processing)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLv9iQK0HOlX"
   },
   "source": [
    "### 1. 텍스트 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텍스트 전처리 : 텍스트 분석을 진행하기 전에 분석 목적에 맞게 변형,가공하는 과정이다.\n",
    "- 적용 패키지 : 파이썬 내장 함수와 더불어 한글은 KoNLPy, 영어는 NLTK로 전처리한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전처리 절차 : 전처리 절차는 말뭉치(코퍼스)의 형태나 분석하고자 하는 목적에 따라 유연하게 적용한다.\n",
    "\n",
    "   <img src='images/Pre-processing.png' width='980px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 토큰화(Tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 토큰화 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ① 토큰화의 개념 및 처리 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 토큰화 : 말뭉치(corpus)에서 텍스트를 토큰(token)이라 불리는 의미있는 단위로 나누는 것을 토큰화라고 한다.(단어 또는 문장 단위로 토큰화를 진행)\n",
    "   - 말뭉치(corpus) : 특정한 목적을 가지고 수집한 텍스트 데이터이다.\n",
    "   - 토큰(token) : 더 이상 분해될 수 없는 최소한의 의미를 갖는 단위이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqPZHQZPzFvc"
   },
   "source": [
    "- 특수문자에 대한 처리\n",
    "  - 단어에 일반적으로 사용되는 알파벳, 숫자와는 다르게 특수문자는 별도의 처리가 필요하다.            \n",
    "  - 일괄적으로 단어의 특수문자를 제거하는 방법도 있지만 특수문자가 단어에 특별한 의미를 가질 때 이를 학습에 반영시키지 못할 수도 있다.\n",
    "  - 특수문자에 대한 일괄적인 제거보다는 데이터의 특성을 파악하고, 처리를 하는 것이 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrZTwnlTyzYV"
   },
   "source": [
    "- 특정 단어에 대한 토큰 분리 방법\n",
    "  - 한 단어지만 토큰으로 분리할 때 판단되는 문자들로 이루어진 `we're, United Kingdom` 등의 단어는 어떻게 분리해야 할지 선택이 필요하다.   \n",
    "  - `we're`은 한 단어이나 분리해도 단어의 의미에 별 영향을 끼치진 않지만 `United Kingdom`은 두 단어가 모여 특정 의미를 가리켜 분리해선 안된다.\n",
    "  - 사용자가 단어의 특성을 고려해 토큰을 분리하는 것이 학습에 유리하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ② 한국어 토큰화의 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한국어 처리의 어려움 : 한국어는 어간에 접사가 붙어 의미와 문법적 기능이 변화하는 ‘교착어’로 인공지능 모델링이 어렵다.\n",
    "\n",
    "   <img src='./images/korean.png' width='980px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한국어 처리를 위한 패키지\n",
    "   - `KoNLPy` : 한글을  쉽고 간결하게 처리할 수 있도록 만들어진 오픈소스 패키지다. -> https://konlpy.org/ko/latest/\n",
    "   - `kiwipiepy` : 한국어 형태소 분석기인 Kiwi(Korean Intelligent Word Identifier)의 Python 모듈이다. -> https://bab2min.github.io/kiwipiepy/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9_k9rA6v0KM"
   },
   "source": [
    "#### 2) 단어 토큰화(Word Tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ① 파이썬 내장 함수로 텍스트 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'When you have faults, do not fear to abandon them.'\n",
    "# 허물이 있다면, 버리기를 두려워 말라. -공자- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 공백을 기준으로 단어를 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_PDCM7YwEi9"
   },
   "source": [
    "##### ② NLTK 영어 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NLTK 환경설정\n",
    "    - 'nltk_data' 폴더를 아래의 폴더에 압축 풀기\n",
    "    - C:Users\\poscouser\\AppData\\Roaming\\nltk_data\n",
    "    - 'poscouser' 폴더명은 PC 계정에 따라 다를 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - 'nltk' 패키지의 `tokenize` 모듈을 사용해 손쉽게 구현 가능하다.\n",
    "   - 단어 토큰화는 `word_tokenize()` 함수를 사용해 구현 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXkXYwoywHAl"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iRYvPrOZbGQ"
   },
   "source": [
    "-  PoS(Parts-of-Speech) 태깅: PoS는 품사를 의미하며, PoS 태깅은 문장 내에서 단어에 해당하는 각 품사를 태깅하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvoGzfP2AjqJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWUanibELmmi"
   },
   "source": [
    "- NLTK PoS 태그 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RGD-0sVAwaV"
   },
   "source": [
    "| Number | Tag | Description | 설명 |\n",
    "| -- | -- | -- | -- |\n",
    "| 1 | `CC` | Coordinating conjunction |\n",
    "| 2 | `CD` | Cardinal number |\n",
    "| 3 | `DT` | Determiner | 한정사\n",
    "| 4 | `EX` | Existential there |\n",
    "| 5 | `FW` | Foreign word | 외래어 |\n",
    "| 6 | `IN` | Preposition or subordinating conjunction | 전치사 또는 종속 접속사 |\n",
    "| 7 | `JJ` | Adjective | 형용사 |\n",
    "| 8 | `JJR` | Adjective, comparative | 헝용사, 비교급 |\n",
    "| 9 | `JJS` | Adjective, superlative | 형용사, 최상급 |\n",
    "| 10 | `LS` | List item marker |\n",
    "| 11 | `MD` | Modal |\n",
    "| 12 | `NN` | Noun, singular or mass | 명사, 단수형 |\n",
    "| 13 | `NNS` | Noun, plural | 명사, 복수형 |\n",
    "| 14 | `NNP` | Proper noun, singular | 고유명사, 단수형 |\n",
    "| 15 | `NNPS` | Proper noun, plural | 고유명사, 복수형 |\n",
    "| 16 | `PDT` | Predeterminer | 전치한정사 |\n",
    "| 17 | `POS` | Possessive ending | 소유형용사 |\n",
    "| 18 | `PRP` | Personal pronoun | 인칭 대명사 |\n",
    "| 19 | `PRP$` | Possessive pronoun | 소유 대명사 |\n",
    "| 20 | `RB` | Adverb | 부사 |\n",
    "| 21 | `RBR` | Adverb, comparative | 부사, 비교급 |\n",
    "| 22 | `RBS` | Adverb, superlative | 부사, 최상급 |\n",
    "| 23 | `RP` | Particle |\n",
    "| 24 | `SYM` | Symbol | 기호\n",
    "| 25 | `TO` | to |\n",
    "| 26 | `UH` | Interjection | 감탄사 |\n",
    "| 27 | `VB` | Verb, base form | 동사, 원형 |\n",
    "| 28 | `VBD` | Verb, past tense | 동사, 과거형 |\n",
    "| 29 | `VBG` | Verb, gerund or present participle | 동사, 현재분사 |\n",
    "| 30 | `VBN` | Verb, past participle | 동사, 과거분사 |\n",
    "| 31 | `VBP` | Verb, non-3rd person singular present | 동사, 비3인칭 단수 |\n",
    "| 32 | `VBZ` | Verb, 3rd person singular present | 동사, 3인칭 단수 |\n",
    "| 33 | `WDT` | Wh-determiner |\n",
    "| 34 | `WP` | Wh-pronoun |\n",
    "| 35 | `WP$` | Possessive wh-pronoun |\n",
    "| 36 | `WRB` | Wh-adverb |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ③ Kiwipiepy 한국어 형태소 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한국어는 공백으로 단어를 분리해도 조사, 접속사 등이 남아 분석에 어려움이 있다.\n",
    "- 이를 해결해주는 한국어 토큰화는 조사, 접속사를 분리해주거나 제거한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECKpbnSaZnXd"
   },
   "source": [
    "- 형태소 분석(Morphological Analysis) : 더 이상 분해될 수 없는 최소한의 의미를 갖는 단위인 형태소를 추출하는 것이다.\n",
    "   - 형태소에는 어간(stem)과 접사(affix)가 있다.\n",
    "   - 어간 : 단어의 의미를 담고 있는 단어의 핵심 부분이다.\n",
    "   - 접사 : 단어에 추가적인 의미를 주는 부분이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3gDC2NOvZnXe"
   },
   "outputs": [],
   "source": [
    "s = '자신감 있는 표정을 지으면 자신감이 생긴다.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  kiwi 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nqCnRA7-zKwp"
   },
   "outputs": [],
   "source": [
    "from kiwipiepy import Kiwi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y18tRWoOZnXe"
   },
   "source": [
    "-  형태소 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fW_-oiQTZnXf"
   },
   "source": [
    "-  명사 추출(조사, 접속사 등을 제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRSbGlYwZnXf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kiwipiepy PoS 태그 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-7btt{border-color:inherit;font-weight:bold;vertical-align:top}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:middle}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-7btt\">대분류</th>\n",
    "    <th class=\"tg-7btt\">태그</th>\n",
    "    <th class=\"tg-7btt\">설명</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td rowspan=5 class=\"tg-0pky\">체언(N)</td>\n",
    "    <td class=\"tg-0pky\">NNG</td>\n",
    "    <td class=\"tg-0pky\">일반 명사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">NNP</td>\n",
    "    <td class=\"tg-0pky\">고유 명사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">NNB</td>\n",
    "    <td class=\"tg-0pky\">의존 명사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">NR</td>\n",
    "    <td class=\"tg-0pky\">수사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">NP</td>\n",
    "    <td class=\"tg-0pky\">대명사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=5 class=\"tg-0pky\">용언(V)</td>\n",
    "    <td class=\"tg-0pky\">VV</td>\n",
    "    <td class=\"tg-0pky\">동사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">VA</td>\n",
    "    <td class=\"tg-0pky\">형용사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">VX</td>\n",
    "    <td class=\"tg-0pky\">보조 용언</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">VCP</td>\n",
    "    <td class=\"tg-0pky\">긍정 지시사(이다)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">VCN</td>\n",
    "    <td class=\"tg-0pky\">부정 지시사(아니다)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">관형사</td>\n",
    "    <td class=\"tg-0pky\">MM</td>\n",
    "    <td class=\"tg-0pky\">관형사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=2 class=\"tg-0pky\">부사(MA)</td>\n",
    "    <td class=\"tg-0pky\">MAG</td>\n",
    "    <td class=\"tg-0pky\">일반 부사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">MAJ</td>\n",
    "    <td class=\"tg-0pky\">접속 부사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">감탄사</td>\n",
    "    <td class=\"tg-0pky\">IC</td>\n",
    "    <td class=\"tg-0pky\">감탄사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=9 class=\"tg-0pky\">조사(J)</td>\n",
    "    <td class=\"tg-0pky\">JKS</td>\n",
    "    <td class=\"tg-0pky\">주격 조사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">JKC</td>\n",
    "    <td class=\"tg-0pky\">보격 조사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">JKG</td>\n",
    "    <td class=\"tg-0pky\">관형격 조사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">JKO</td>\n",
    "    <td class=\"tg-0pky\">목적격 조사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">JKB</td>\n",
    "    <td class=\"tg-0pky\">부사격 조사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">JKV</td>\n",
    "    <td class=\"tg-0pky\">호격 조사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">JKQ</td>\n",
    "    <td class=\"tg-0pky\">인용격 조사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">JX</td>\n",
    "    <td class=\"tg-0pky\">보조사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">JC</td>\n",
    "    <td class=\"tg-0pky\">접속 조사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=5 class=\"tg-0pky\">어미(E)</td>\n",
    "    <td class=\"tg-0pky\">EP</td>\n",
    "    <td class=\"tg-0pky\">선어말 어미</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">EF</td>\n",
    "    <td class=\"tg-0pky\">종결 어미</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">EC</td>\n",
    "    <td class=\"tg-0pky\">연결 어미</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">ETN</td>\n",
    "    <td class=\"tg-0pky\">명사형 전성 어미</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">ETM</td>\n",
    "    <td class=\"tg-0pky\">관형형 전성 어미</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">접두사</td>\n",
    "    <td class=\"tg-0pky\">XPN</td>\n",
    "    <td class=\"tg-0pky\">체언 접두사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=4 class=\"tg-0pky\">접미사(XS)</td>\n",
    "    <td class=\"tg-0pky\">XSN</td>\n",
    "    <td class=\"tg-0pky\">명사 파생 접미사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">XSV</td>\n",
    "    <td class=\"tg-0pky\">동사 파생 접미사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">XSA</td>\n",
    "    <td class=\"tg-0pky\">형용사 파생 접미사</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">XSM</td>\n",
    "    <td class=\"tg-0pky\">부사 파생 접미사*</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">어근</td>\n",
    "    <td class=\"tg-0pky\">XR</td>\n",
    "    <td class=\"tg-0pky\">어근</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=11  class=\"tg-0pky\">부호, 외국어, 특수문자(S)</td>\n",
    "    <td class=\"tg-0pky\">SF</td>\n",
    "    <td class=\"tg-0pky\">종결 부호(. ! ?)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">SP</td>\n",
    "    <td class=\"tg-0pky\">구분 부호(, / : ;)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">SS</td>\n",
    "    <td class=\"tg-0pky\">인용 부호 및 괄호(' \" ( ) [ ] &lt; &gt; { } ― ‘ ’ “ ” ≪&nbsp;&nbsp;&nbsp;≫ 등)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">SSO</td>\n",
    "    <td class=\"tg-0pky\">SS 중 여는 부호*</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">SSC</td>\n",
    "    <td class=\"tg-0pky\">SS 중 닫는 부호*</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">SE</td>\n",
    "    <td class=\"tg-0pky\">줄임표(…)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">SO</td>\n",
    "    <td class=\"tg-0pky\">붙임표(- ~)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">SW</td>\n",
    "    <td class=\"tg-0pky\">기타 특수 문자</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">SL</td>\n",
    "    <td class=\"tg-0pky\">알파벳(A-Z a-z)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">SH</td>\n",
    "    <td class=\"tg-0pky\">한자</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">SN</td>\n",
    "    <td class=\"tg-0pky\">숫자(0-9)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">분석 불능</td>\n",
    "    <td class=\"tg-0pky\">UN</td>\n",
    "    <td class=\"tg-0pky\">분석 불능*</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=5 class=\"tg-0pky\">웹(W)</td>\n",
    "    <td class=\"tg-0pky\">W_URL</td>\n",
    "    <td class=\"tg-0pky\">URL 주소*</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">W_EMAIL</td>\n",
    "    <td class=\"tg-0pky\">이메일 주소*</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">W_HASHTAG</td>\n",
    "    <td class=\"tg-0pky\">해시태그(#abcd)*</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">W_MENTION</td>\n",
    "    <td class=\"tg-0pky\">멘션(@abcd)*</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">W_SERIAL</td>\n",
    "    <td class=\"tg-0pky\">일련번호(전화번호, 통장번호, IP주소 등)*</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">기타</td>\n",
    "    <td class=\"tg-0pky\">Z_CODA</td>\n",
    "    <td class=\"tg-0pky\">덧붙은 받침*</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcmIjFyRwJpW"
   },
   "source": [
    "#### 3) 문장 토큰화(Setence Tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkJ60tlTv7Ux"
   },
   "outputs": [],
   "source": [
    "s = \"Life is like a box of chocolates.\\nYou never know what you're gonna get.\"\n",
    "# 인생은 마치 초콜릿 상자와도 같다. 당신이 무엇을 얻게 될지 모르기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Jkvs6Jov7QF"
   },
   "source": [
    "##### ① 줄바꿈 문자('\\n')를 기준으로 문장을 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDSxHUHTwVzG"
   },
   "source": [
    "##### ② nltk 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oR8iHWiwV6f"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYJCYXP65yVk"
   },
   "source": [
    "##### ③ Kiwipiepy 이용(한국어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '한 가지 생각을 선택하라. 그 생각을 당신의 삶으로 만들어라. 그걸 생각하고, 꿈꾸고, 그에 기반해서 살아가라. 당신의 몸의 모든 부분, 뇌, 근육, 신경을 그 생각으로 가득 채우고 다른 생각은 다 내버려둬라. 이것이 성공하는 방법이다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmDuyhjxugFN"
   },
   "source": [
    "### 3. 정제(Cleaning) 및 정규화(Normalizaion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정제 : 데이터에서 손상되거나 부정확한 부분, 관련이 없는 부분을 식별한 뒤에 수정 및 삭제, 대체 등을 하는 과정이다.\n",
    "- 정규화 : 데이터에서 표현방법이 다른 단어들을 통합시켜 같은 단어로 통합하는 과정이다.\n",
    "- 토큰화 작업 전·후 실시하나 한글에서는 명사 만 추출하여 사용할 경우 어느 정도 정제화가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정제 및 정규화 방법\n",
    "\n",
    "   <img src='./images/re.png' width='1000px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 불용어(Stopword) 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fj2rvWzwuy7o"
   },
   "source": [
    "- 불용어(stop words): 문장 형성에 중요한 구문록적 가치를 지니고 있지만 무시할 수 있거나 최소한의 의미적 가치를 지닌 단어이다.\n",
    "- 주로 접속사, 관사, 부사, 대명사, 일반동사 등 자연어에 포함되어 있는 정보를 담지 않는 단어들이 불용어에 속한다.\n",
    "- 영어의 전치사(on, in), 한국어의 조사(을, 를) 등은 분석에 필요하지 않은 경우가 많다.\n",
    "- 길이가 짧은 단어, 등장 빈도 수가 적은 단어들도 분석에 큰 영향을 주지 않는다.\n",
    "- 일반적으로 사용되는 도구들은 해당 단어들을 제거해주지만 완벽하게 제거되지는 않는다.\n",
    "- 사용자가 불용어 사전을 만들어 해당 단어들을 제거하는 것이 좋다.\n",
    "- 도구들이 걸러주지 않는 전치사, 조사 등을 불용어 사전을 만들어 불필요한 단어들을 제거한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ① 단어를 분리하여 불용어로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hjFp9u9quy_t"
   },
   "outputs": [],
   "source": [
    "stop_words = 'on in the'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stop_words.split(' ')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ② 설정된 불용어를 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9nKwwtR6uzCr"
   },
   "outputs": [],
   "source": [
    "sentence = 'singer on the stage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = sentence.split(' ')\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = []\n",
    "for noun in sentence:\n",
    "      if noun not in stop_words:\n",
    "            nouns.append(noun)\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykTS2yeMMEXF"
   },
   "source": [
    "##### ③ `nltk` 패키지의 불용어 리스트 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XlDpO3e-MHwa"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 불용어 리스트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1jC408N2MRR0"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zShCTozjMYWG"
   },
   "outputs": [],
   "source": [
    "s = 'If you do not walk today. you will have to run tomorrow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(s)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qd_gC78EOPdv"
   },
   "outputs": [],
   "source": [
    "no_stopwords = []\n",
    "\n",
    "for w in words:\n",
    "      if w not in stop_words:\n",
    "            no_stopwords.append(w)\n",
    "print(no_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ④ Kiwipiepy 패키지의 불용어 리스트 사용(한국어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy.utils import Stopwords\n",
    "\n",
    "stopwords = Stopwords()\n",
    "token_kr = []\n",
    "\n",
    "token_text = kiwi.tokenize(text, stopwords=stopwords)\n",
    "\n",
    "for token in token_text:\n",
    "      token_kr.append(token.form)\n",
    "      \n",
    "print(token_kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4_svyI2myE3"
   },
   "source": [
    "#### 2) 단수화(Singularize)와 복수화(Pluralize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ① 단수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tDE8Aeumxml"
   },
   "outputs": [],
   "source": [
    "words = 'apples bananas oranges'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "textblob = TextBlob(words)\n",
    "\n",
    "print(textblob.words)\n",
    "print(textblob.words.singularize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ② 복수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLqLAg6Snfi8"
   },
   "outputs": [],
   "source": [
    "words = 'car train airplane'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textblob = TextBlob(words)\n",
    "\n",
    "print(textblob.words)\n",
    "print(textblob.words.pluralize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-zauW83XwJ8"
   },
   "source": [
    "### 4. 표제어(Lemmatization) 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 표제어(Lemma) : `기본 사전형 단어`의 의미를 가진다.\n",
    "- 표제어 추출 : 정확하게 의도된 품사와 문장에 있는 단어의 의미를 식별하는 과정이다.\n",
    "- 표제어 추출은 단어들이 다른 형태를 가지더라도, 그 뿌리 단어를 찾아가서 단어의 개수를 줄일 수 있는지 판단한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTHh2W06TlPm"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LF_jyPwaTzV5"
   },
   "outputs": [],
   "source": [
    "lem = lemmatizer.lemmatize('application')\n",
    "lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrFilM4jWF9p"
   },
   "outputs": [],
   "source": [
    "lem = lemmatizer.lemmatize('lives')\n",
    "lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MoKJNaJ8WT2x"
   },
   "outputs": [],
   "source": [
    "lem = lemmatizer.lemmatize('catches')\n",
    "lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = lemmatizer.lemmatize('education')\n",
    "lem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-9i7ubNX0mD"
   },
   "source": [
    "### 5. 어간(Stemming) 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - 형태소에는 어간(stem)과 접사(affix)가 있다.\n",
    "   - 어간 : 단어의 의미를 담고 있는 단어의 핵심 부분이다.\n",
    "   - 접사 : 단어에 추가적인 의미를 주는 부분이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_28SNykTEbf"
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LCwnOPFNTP2v"
   },
   "outputs": [],
   "source": [
    "stem = stemmer.stem('application')\n",
    "stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6O5VoWcTQuO"
   },
   "outputs": [],
   "source": [
    "stem = stemmer.stem('beginning')\n",
    "stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHvL3FirTUQO"
   },
   "outputs": [],
   "source": [
    "stem = stemmer.stem('catches')\n",
    "stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4B7VXlfMTiAj"
   },
   "outputs": [],
   "source": [
    "stem = stemmer.stem('education')\n",
    "stem"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a86e7cc0d3fd2b3984d90a12bd1fbcf5461ee2e2e08ec83f39bc9fc9adb9109f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
